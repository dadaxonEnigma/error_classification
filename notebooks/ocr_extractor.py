import cv2
import numpy as np
from PIL import Image
import pytesseract
import os
import re

# –£–∫–∞–∂–∏ –ø—É—Ç—å –∫ Tesseract, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"


# =========================================================
# üî¥ 1. –ü–æ–∏—Å–∫ –∫—Ä–∞—Å–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
# =========================================================
def find_red_region(img_path, show_debug=True):
    img = cv2.imread(img_path)
    if img is None:
        raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {img_path}")

    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

    lower_red1 = np.array([0, 100, 100])
    upper_red1 = np.array([10, 255, 255])
    lower_red2 = np.array([160, 100, 100])
    upper_red2 = np.array([179, 255, 255])

    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
    mask = cv2.bitwise_or(mask1, mask2)

    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not contours:
        print("‚ùå –ö—Ä–∞—Å–Ω–∞—è –æ–±–ª–∞—Å—Ç—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
        return None

    contour = max(contours, key=cv2.contourArea)
    x, y, w, h = cv2.boundingRect(contour)

    if show_debug:
        debug_img = img.copy()
        cv2.rectangle(debug_img, (x, y), (x + w, y + h), (0, 255, 0), 3)
        save_path = os.path.join(os.path.dirname(img_path), "debug_detected_error.jpg")
        cv2.imwrite(save_path, debug_img)
        print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ä–∞–º–∫–æ–π: {save_path}")

    cropped = img[y:y+h, x:x+w]
    return cropped


def extract_status_text(img_path, langs="eng+rus+uzb", show_debug=True):
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç–∞—Ç—É—Å (Approved / Not approved / Tasdiqlangan / Tasdiqlanmagan / Bekor Qilingan / –û–¥–æ–±—Ä–µ–Ω–æ)
    —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∑–µ–ª—ë–Ω—ã—Ö –∏ –∂—ë–ª—Ç—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ –±–µ–ª–æ–º —Ñ–æ–Ω–µ.
    """
    import re

    img = cv2.imread(img_path)
    if img is None:
        raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {img_path}")

    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

    # üé® –î–∏–∞–ø–∞–∑–æ–Ω—ã —Ü–≤–µ—Ç–∞
    lower_green = np.array([35, 40, 40])
    upper_green = np.array([90, 255, 255])
    lower_yellow = np.array([15, 50, 50])
    upper_yellow = np.array([35, 255, 255])

    # –ú–∞—Å–∫–∏
    mask_green = cv2.inRange(hsv, lower_green, upper_green)
    mask_yellow = cv2.inRange(hsv, lower_yellow, upper_yellow)
    mask = cv2.bitwise_or(mask_green, mask_yellow)

    # –ò–∑–æ–ª–∏—Ä—É–µ–º —Ü–≤–µ—Ç–Ω–æ–π —Ç–µ–∫—Å—Ç
    result = cv2.bitwise_and(img, img, mask=mask)
    gray = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)

    # –£—Å–∏–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ç—Ä–∞—Å—Ç –∏ –∏–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º
    gray = cv2.convertScaleAbs(gray, alpha=3.0, beta=0)
    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    if show_debug:
        debug_path = os.path.join(os.path.dirname(img_path), "debug_status_mask.jpg")
        cv2.imwrite(debug_path, thresh)
        print(f"üß© –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –º–∞—Å–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {debug_path}")

    # OCR –ø–æ —Ü–≤–µ—Ç–Ω—ã–º –Ω–∞–¥–ø–∏—Å—è–º
    data = pytesseract.image_to_data(
        thresh, lang=langs, config="--psm 6", output_type=pytesseract.Output.DICT
    )

    found_status = None
    best_conf = 0

    for i, word in enumerate(data["text"]):
        if not word.strip():
            continue

        conf_raw = data["conf"][i]
        try:
            conf = int(float(conf_raw))
        except (ValueError, TypeError):
            conf = 0

        clean_word = re.sub(r'[^A-Za-z–ê-–Ø–∞-—è]', '', word).lower()

        if conf < 40:
            continue

        if clean_word in ["approved", "tasdiqlangan", "–æ–¥–æ–±—Ä–µ–Ω–æ"]:
            found_status = "Approved"
            best_conf = conf
        elif clean_word in ["notapproved", "radetilgan", "–Ω–µ–æ–¥–æ–±—Ä–µ–Ω–æ"]:
            found_status = "Not approved"
            best_conf = conf

    if found_status:
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω —Å—Ç–∞—Ç—É—Å: {found_status} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å {best_conf}%)")
        return found_status
    else:
        print("‚ùå –°—Ç–∞—Ç—É—Å –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return "‚ùå –°—Ç–∞—Ç—É—Å –Ω–µ –Ω–∞–π–¥–µ–Ω"




# =========================================================
# üß† 2. –£–ª—É—á—à–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ—Å–ª–µ –æ–±—Ä–µ–∑–∫–∏
# =========================================================

def enhance_edges(img):
    """–ü–æ–≤—ã—à–∞–µ—Ç —Ä–µ–∑–∫–æ—Å—Ç—å –∏ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∫–æ–Ω—Ç—É—Ä—ã –±—É–∫–≤."""
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (0, 0), sigmaX=1.5)
    unsharp = cv2.addWeighted(gray, 1.7, blur, -0.7, 0)
    lap = cv2.Laplacian(unsharp, cv2.CV_64F)
    lap = cv2.convertScaleAbs(lap)
    sharpened = cv2.addWeighted(unsharp, 1.0, lap, 0.4, 0)
    return sharpened


def normalize_lighting(gray):
    """–í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –æ—Å–≤–µ—â—ë–Ω–Ω–æ—Å—Ç—å –∏ –ø–æ–≤—ã—à–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç—Ä–∞—Å—Ç."""
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 25))
    tophat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, kernel)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    norm = clahe.apply(tophat)
    return norm


def adaptive_thicken(gray):
    """–î–µ–ª–∞–µ—Ç —Ç–æ–Ω–∫–∏–π —Ç–µ–∫—Å—Ç —á—É—Ç—å –∂–∏—Ä–Ω–µ–µ, –Ω–µ –∏—Å–∫–∞–∂–∞—è —Ñ–æ—Ä–º—É."""
    kernel = np.ones((2, 2), np.uint8)
    edges = cv2.Canny(gray, 30, 100)
    dilated = cv2.dilate(edges, kernel, iterations=1)
    combined = cv2.bitwise_or(gray, dilated)
    return combined


def super_preprocess(image, img_path=None, show_debug=True):
    """
    –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–µ—Ä–µ–¥ OCR.
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—Å–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —ç—Ç–∞–ø—ã.
    """
    base_dir = os.path.dirname(img_path) if img_path else "."

    # üîπ 1. –ü–æ–≤—ã—à–∞–µ–º —Ä–µ–∑–∫–æ—Å—Ç—å
    step1 = enhance_edges(image)
    cv2.imwrite(os.path.join(base_dir, "debug_step1_sharpened.jpg"), step1)


    print(f"üß© –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤—Å–µ —ç—Ç–∞–ø—ã —É–ª—É—á—à–µ–Ω–∏—è –≤: {base_dir}")

    return step1


# =========================================================
# üî§ 3. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
# =========================================================
def extract_error_text(img_path, langs="eng+rus+uzb", show_debug=True):
    red_region = find_red_region(img_path, show_debug=show_debug)
    if red_region is None:
        return "‚ùå –ö—Ä–∞—Å–Ω–∞—è –æ–±–ª–∞—Å—Ç—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"

    processed = super_preprocess(red_region, img_path, show_debug)
    pil_img = Image.fromarray(processed)

    custom_config = r'--oem 3 --psm 6'  # 6 ‚Äî —Ä–µ–∂–∏–º –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
    text = pytesseract.image_to_string(pil_img, lang=langs, config=custom_config)
    return text.strip()


if __name__ == "__main__":
    path = "../data/raw/test1_8.jpg"  # –£–∫–∞–∂–∏ –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é

    print("üîç –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")

    # 1Ô∏è‚É£ –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∫—Ä–∞—Å–Ω—É—é –æ–±–ª–∞—Å—Ç—å (–æ—à–∏–±–∫–∞)
    try:
        text = extract_error_text(path, show_debug=True)
        if text and "‚ùå" not in text and len(text.strip()) > 2:
            print("\nüìú –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –æ—à–∏–±–∫–∏:")
            print(text)
        else:
            # 2Ô∏è‚É£ –ï—Å–ª–∏ –∫—Ä–∞—Å–Ω–æ–≥–æ –±–∞–Ω–Ω–µ—Ä–∞ –Ω–µ—Ç ‚Äî –∏—â–µ–º —Å—Ç–∞—Ç—É—Å (Approved / Not approved)
            from ocr_extractor import extract_status_text
            status = extract_status_text(path, show_debug=True)
            print("\nüìó –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Å—Ç–∞—Ç—É—Å:")
            print(status)
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")